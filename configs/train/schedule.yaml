# LR scheduler semantics; trainer translates these to PyTorch schedulers.
train:
  scheduler_step_on: batch   # 'batch' or 'epoch'

